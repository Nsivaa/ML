{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from NeuralNetwork import *\n",
    "from utils import *\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying One-Hot Encoding and Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Class        ID  a1_1  a1_2  a1_3  a2_1  a2_2  a2_3  a3_1  a3_2  a4_1  \\\n",
      "0        1  data_153     0     1     0     1     0     0     1     0     0   \n",
      "1        0  data_117     1     0     0     0     0     1     1     0     0   \n",
      "2        1  data_227     0     1     0     0     1     0     0     1     0   \n",
      "3        1  data_416     0     0     1     0     0     1     0     1     1   \n",
      "4        0  data_173     0     1     0     1     0     0     0     1     1   \n",
      "..     ...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
      "119      1  data_297     0     0     1     1     0     0     1     0     0   \n",
      "120      0  data_124     1     0     0     0     0     1     0     1     1   \n",
      "121      0   data_92     1     0     0     0     1     0     0     1     0   \n",
      "122      1  data_216     0     1     0     0     1     0     1     0     0   \n",
      "123      0  data_159     0     1     0     1     0     0     1     0     0   \n",
      "\n",
      "     a4_2  a4_3  a5_1  a5_2  a5_3  a5_4  a6_1  a6_2  \n",
      "0       1     0     1     0     0     0     1     0  \n",
      "1       0     1     0     0     1     0     1     0  \n",
      "2       1     0     0     1     0     0     1     0  \n",
      "3       0     0     0     0     0     1     0     1  \n",
      "4       0     0     0     0     1     0     1     0  \n",
      "..    ...   ...   ...   ...   ...   ...   ...   ...  \n",
      "119     1     0     1     0     0     0     1     0  \n",
      "120     0     0     0     1     0     0     0     1  \n",
      "121     0     1     0     1     0     0     0     1  \n",
      "122     0     1     0     0     0     1     0     1  \n",
      "123     1     0     0     0     0     1     1     0  \n",
      "\n",
      "[124 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "col_names = [\"Class\", \"a1\", \"a2\", \"a3\", \"a4\", \"a5\", \"a6\", \"ID\"]\n",
    "tr_data = pd.read_csv(\"../monk+s+problems/monks-1.train\", sep =\" \",  names = col_names)\n",
    "test_data = pd.read_csv(\"../monk+s+problems/monks-1.test\", sep =\" \",  names = col_names)\n",
    "\n",
    "tr_data = process_monk_data(tr_data)\n",
    "test_data = process_monk_data(test_data)\n",
    "\n",
    "print(tr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'net = NeuralNetwork()\\n\\nn_inputs = tr_data.shape[1] - 2\\n\\nnet.add_input_layer(n_inputs)\\n\\nnet.add_hidden_layer(n_inputs, 4)\\n\\nnet.add_output_layer(4, 1)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''net = NeuralNetwork()\n",
    "\n",
    "n_inputs = tr_data.shape[1] - 2\n",
    "\n",
    "net.add_input_layer(n_inputs)\n",
    "\n",
    "net.add_hidden_layer(n_inputs, 4)\n",
    "\n",
    "net.add_output_layer(4, 1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with Mean Square Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\"epochs\": 500,\n",
    "               \"eta\": 0.5,\n",
    "               \"clip_value\": 1000,\n",
    "               \"hid_act_fun\": \"tanh\",\n",
    "               \"out_act_fun\": \"sigmoid\",\n",
    "               \"cost_fun\": \"mse\",\n",
    "               \"mb\" : 16,\n",
    "               \"momentum\" : 0.01}\n",
    "\n",
    "\n",
    "#losses = net.train(tr_data, hyperparams)  # TANH IS FASTER?? SCRITTO SULLE SLIDE\n",
    "# print(net)\n",
    "# print(net.input_layer.weights)\n",
    "\n",
    "#plot_loss(losses, cost_fun = hyperparams[\"cost_fun\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with Binary Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#RESET THE NETWORK!!!\\n\\nlosses = net.train(tr_data_X, tr_data_Y, epochs=1000,\\n                   eta=0.5, clip_value=None, hid_act_fun=\"tanh\", out_act_fun=\"sigmoid\", cost_fun=\"b_ce\")  # TANH IS FASTER?? SCRITTO SULLE SLIDE\\n# print(net)\\n# print(net.input_layer.weights)\\n\\nplot_loss(losses, cost_fun=\"b_ce\")\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#RESET THE NETWORK!!!\n",
    "\n",
    "losses = net.train(tr_data_X, tr_data_Y, epochs=1000,\n",
    "                   eta=0.5, clip_value=None, hid_act_fun=\"tanh\", out_act_fun=\"sigmoid\", cost_fun=\"b_ce\")  # TANH IS FASTER?? SCRITTO SULLE SLIDE\n",
    "# print(net)\n",
    "# print(net.input_layer.weights)\n",
    "\n",
    "plot_loss(losses, cost_fun=\"b_ce\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Monk 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_eta = net.k_fold(3, tr_data, hyperparams, \"eta\", [0.01, 0.05, 0.1,0.5, 0.8, 1])\n",
    "#print(best_eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nsiva/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'epochs' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 17\u001b[0m\n\u001b[1;32m      1\u001b[0m grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meta\u001b[39m\u001b[38;5;124m\"\u001b[39m : [\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmb\u001b[39m\u001b[38;5;124m\"\u001b[39m : [\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m64\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip_value\u001b[39m\u001b[38;5;124m\"\u001b[39m : [\u001b[38;5;241m1000\u001b[39m]\n\u001b[1;32m     11\u001b[0m     } \n\u001b[1;32m     14\u001b[0m search_space \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(itertools\u001b[38;5;241m.\u001b[39mproduct(grid[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meta\u001b[39m\u001b[38;5;124m\"\u001b[39m], grid[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmb\u001b[39m\u001b[38;5;124m\"\u001b[39m], grid[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmomentum\u001b[39m\u001b[38;5;124m\"\u001b[39m], grid[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m], grid[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_neurons\u001b[39m\u001b[38;5;124m\"\u001b[39m], grid[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     15\u001b[0m                             grid[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhid_act_fun\u001b[39m\u001b[38;5;124m\"\u001b[39m], grid[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout_act_fun\u001b[39m\u001b[38;5;124m\"\u001b[39m], grid[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip_value\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m---> 17\u001b[0m configs \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtr_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_inputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtr_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/env/ML/project/utils.py:35\u001b[0m, in \u001b[0;36mgrid_search\u001b[0;34m(k, data, search_space, n_inputs, n_outputs)\u001b[0m\n\u001b[1;32m     32\u001b[0m     output_layer \u001b[38;5;241m=\u001b[39m Layer(parameters[\u001b[38;5;241m5\u001b[39m], n_outputs)\n\u001b[1;32m     33\u001b[0m     net \u001b[38;5;241m=\u001b[39m NeuralNetwork(input_layer, hidden_layers, output_layer)\n\u001b[0;32m---> 35\u001b[0m     val_errors[parameters] \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# min_err = np.min(val_errors.values())\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# return val_errors[min_err]\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m val_errors\n",
      "File \u001b[0;32m~/env/ML/project/NeuralNetwork.py:270\u001b[0m, in \u001b[0;36mNeuralNetwork.k_fold\u001b[0;34m(self, k, data, parameters)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold \u001b[38;5;129;01min\u001b[39;00m folds:\n\u001b[1;32m    269\u001b[0m     tr_set \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m folds \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mSeries\u001b[38;5;241m.\u001b[39mequals(f, fold)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     valid_labels \u001b[38;5;241m=\u001b[39m fold[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m    272\u001b[0m     valid_data \u001b[38;5;241m=\u001b[39m fold\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m\"\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/env/ML/project/NeuralNetwork.py:211\u001b[0m, in \u001b[0;36mNeuralNetwork.train\u001b[0;34m(self, tr_data, params)\u001b[0m\n\u001b[1;32m    209\u001b[0m n \u001b[38;5;241m=\u001b[39m tr_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    210\u001b[0m errors \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m1\u001b[39m, \u001b[43mepochs\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;66;03m# shuffle dataframe before each epoch\u001b[39;00m\n\u001b[1;32m    213\u001b[0m     tr_data \u001b[38;5;241m=\u001b[39m tr_data\u001b[38;5;241m.\u001b[39msample(frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, n \u001b[38;5;241m/\u001b[39m mb):\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;66;03m# tra uno step e l'altro azzero gli accumulatori dei gradienti per ogni layer\u001b[39;00m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'epochs' referenced before assignment"
     ]
    }
   ],
   "source": [
    "grid = {\n",
    "    \"eta\" : [0.1, 0.2, 0.5, 0.8, 1],\n",
    "    \"mb\" : [8, 16, 32, 64],\n",
    "    \"momentum\" : [0.01, 0.05, 0.1],\n",
    "    \"n_layers\" : [2, 5, 10, 20],\n",
    "    \"n_neurons\" : [10, 20, 30],\n",
    "    \"epochs\" : [500],\n",
    "    \"hid_act_fun\" : [\"tanh\"],\n",
    "    \"out_act_fun\" : [\"sigmoid\"],\n",
    "    \"clip_value\" : [1000]\n",
    "    } \n",
    "\n",
    "\n",
    "search_space = list(itertools.product(grid[\"eta\"], grid[\"mb\"], grid[\"momentum\"], grid[\"n_layers\"], grid[\"n_neurons\"], grid[\"epochs\"],\n",
    "                            grid[\"hid_act_fun\"], grid[\"out_act_fun\"], grid[\"clip_value\"]))\n",
    "\n",
    "configs = grid_search(10, tr_data, search_space, n_inputs = tr_data.shape[1] - 2, n_outputs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
