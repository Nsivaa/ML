{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "import warnings\n",
    "# to ignore pandas warning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from NeuralNetwork import  *\n",
    "from Ensemble import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tr-set is split in 70% to perform 5-fold cross validation on models, 10% for early stopping and 20% as internal test-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ('Input1', 'Input2', 'Input3', 'Input4', 'Input5', 'Input6',\n",
    "             'Input7', 'Input8', 'Input9', 'Input10', 'TARGET_x', 'TARGET_y', 'TARGET_z')\n",
    "\n",
    "if os.path.isfile(\"train_split.csv\"):\n",
    "    tr_data = pd.read_csv(\"train_split.csv\",\n",
    "                   skiprows=1, usecols=[i for i in range(1, 14)], names=col_names)\n",
    "    test_data = pd.read_csv(\"test_split.csv\",\n",
    "                   skiprows=1, usecols=[i for i in range(1, 14)], names=col_names)\n",
    "    es_data = pd.read_csv(\"es_split.csv\",\n",
    "                   skiprows=1, usecols=[i for i in range(1, 14)], names=col_names)\n",
    "else:\n",
    "    data = pd.read_csv(\"../ML-23-PRJ-Package/ML-CUP23-TR.csv\",\n",
    "                   skiprows=7, usecols=[i for i in range(1, 14)], names=col_names)\n",
    "    data = data.sample(frac=1)\n",
    "    #SPLIT 80/20 FOR TRAIN/TEST\n",
    "    folds = np.array_split(data, 10)\n",
    "    tr_data = pd.concat(folds[2:9])\n",
    "    test_data = pd.concat(folds[0:2])\n",
    "    es_data=folds[9]\n",
    "    tr_data.to_csv(\"train_split.csv\")\n",
    "    test_data.to_csv(\"test_split.csv\")\n",
    "    es_data.to_csv(\"es_split.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch\n",
    "We will test some hyperparameter combinations in order to get the best model.\n",
    "<p> Every model is trained with a 5-fold cross , using as tr-set a 70% split on the original tr-set (10% is used for early stopping), MSE is used as a score on the validation set (within the 5-fold) to get the best model. \n",
    "<p> The following is only one of the grid search performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullBatch = tr_data.shape[0]*0.8\n",
    "grid={\n",
    "\"eta\" : [0.001,0.005,0.0001],\n",
    "    \"mb\" : [1,8, 128, fullBatch],\n",
    "    \"momentum\" : [0.9,0.6,0.5,0.7,0.8,0.95],\n",
    "    \"n_layers\" : [2],\n",
    "    \"n_neurons\" : [50,100,150,200],\n",
    "    \"epochs\" : [500],\n",
    "    \"clip_value\" : [None],\n",
    "    \"hid_act_fun\" : [\"tanh\"],\n",
    "    \"out_act_fun\" : [\"linear\"],\n",
    "    \"cost_fun\" : [\"eucl\"],\n",
    "    \"ridge_lambda\": [None, 1e-8],\n",
    "    \"lasso_lambda\": [None],\n",
    "    \"decay_max_steps\": [None, 100],\n",
    "    \"decay_min_value\": [10],\n",
    "    \"es_patience\": [30]\n",
    "}\n",
    "\n",
    "search_space=get_search_space(grid)\n",
    "print(len(search_space))\n",
    "parallel_grid_search(k = 5, data = tr_data, es_data=es_data, search_space=search_space, n_inputs=10, n_outputs=3,type=\"cup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we pick the best 5 models out of the grid search and will use them as an ensemble model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best results:\n",
    "\n",
    "1. {'eta': 0.0001, 'mb': 1, 'momentum': 0.8, 'n_layers': 3, 'n_neurons': 200, 'epochs': 500, 'clip_value': None, 'hid_act_fun': 'tanh', 'out_act_fun': 'linear', 'cost_fun': 'eucl', 'ridge_lambda': 1e-08, 'lasso_lambda': None, 'decay_max_steps': None, 'decay_min_value': 10, 'es_patience': 30}<br>\n",
    "Validation mean = 0.5776027113455716, Variance = 0.0026117155270263376<br>\n",
    "Training mean (ES) = 0.2442599815747089\n",
    "\n",
    "2. {'eta': 0.0001, 'mb': 1, 'momentum': 0.6, 'n_layers': 3, 'n_neurons': 200, 'epochs': 500, 'clip_value': None, 'hid_act_fun': 'tanh', 'out_act_fun': 'linear', 'cost_fun': 'eucl', 'ridge_lambda': 1e-08, 'lasso_lambda': None, 'decay_max_steps': None, 'decay_min_value': 10, 'es_patience': 30}<br>\n",
    "Validation mean = 0.6003179533234724, Variance = 0.001471646127359402<br>\n",
    "Training mean (ES) = 0.2625431767735682\n",
    "\n",
    "3. {'eta': 0.0001, 'mb': 1, 'momentum': 0.9, 'n_layers': 2, 'n_neurons': 200, 'epochs': 500, 'clip_value': None, 'hid_act_fun': 'tanh', 'out_act_fun': 'linear', 'cost_fun': 'eucl', 'ridge_lambda': None, 'lasso_lambda': None, 'decay_max_steps': None, 'decay_min_value': 10, 'es_patience': 30}<br>\n",
    "Validation mean = 0.6108271204955864, Variance = 0.002266016486143601<br>\n",
    "Training mean (ES) = 0.25655232735599054\n",
    "\n",
    "4. {'eta': 0.0001, 'mb': 8, 'momentum': 0.9, 'n_layers': 3, 'n_neurons': 200, 'epochs': 500, 'clip_value': None, 'hid_act_fun': 'tanh', 'out_act_fun': 'linear', 'cost_fun': 'eucl', 'ridge_lambda': None, 'lasso_lambda': None, 'decay_max_steps': None, 'decay_min_value': 10, 'es_patience': 30}<br>\n",
    "Validation mean = 0.617711172518093, Variance = 0.0056700694722032425<br>\n",
    "Training mean (ES) = 0.26035793552839165\n",
    "\n",
    "5. {'eta': 0.0001, 'mb': 1, 'momentum': 0.5, 'n_layers': 3, 'n_neurons': 200, 'epochs': 500, 'clip_value': None, 'hid_act_fun': 'tanh', 'out_act_fun': 'linear', 'cost_fun': 'eucl', 'ridge_lambda': None, 'lasso_lambda': None, 'decay_max_steps': None, 'decay_min_value': 10, 'es_patience': 30}<br>\n",
    "Validation mean = 0.6335390644035537, Variance = 0.004222898732823709<br>\n",
    "Training mean (ES) = 0.2599176722840955\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try to validate the ensemble model comparing the results of a 5-fold performed on the ensemble model and on the best single model (with and without using early stopping).<br>\n",
    "(tr_set + es_data) which is an 80% split of the original training_set is used to perform 5-folds.<br>\n",
    "The best model with the respect to the average validation MEE will be retrained using all the 80% split as the tr_set and tested on the internal test_set (20% split of the original training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr decay is not used as a parameter beacuse there is no model among the best 5 which use it\n",
    "\n",
    "train_params = {\n",
    "    \"eta\" : [0.0001,0.0001,0.0001,0.0001,0.0001],\n",
    "    \"mb\" : [1,1,1,8,1],\n",
    "    \"momentum\" : [0.8,0.6,0.9,0.9,0.5],\n",
    "    \"es_stop\": [0.244,0.262,0.256,0.260,0.259],\n",
    "    \"hid_act_fun\" : \"tanh\",\n",
    "    \"out_act_fun\" : \"linear\",\n",
    "    \"cost_fun\" : \"eucl\",\n",
    "    \"ridge_lambda\": [1e-8,1e-8,None,None,None]\n",
    "}\n",
    "\n",
    "if tr_data.shape[0] == 700:\n",
    "    tr_data = pd.concat([tr_data,es_data])\n",
    "\n",
    "# now we instantiate the 5 best models        \n",
    "modelStructures = [(3,200),(3,200),(2,200),(3,200),(3,200)]\n",
    "\n",
    "\n",
    "tr_mean,valid_mean, valid_var = k_fold_ensemble(5, tr_data,modelStructures, train_params,progress_bar=True,epochs=2000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5-fold mee validation = **0.519**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 fold with es\n",
    "parameters = {\n",
    "    'eta': 0.0001,\n",
    "    'mb': 1,\n",
    "    'momentum': 0.8, \n",
    "    'n_layers': 3, \n",
    "    'n_neurons': 200, \n",
    "    'epochs': 2000, \n",
    "    'clip_value': None, \n",
    "    'hid_act_fun': 'tanh', \n",
    "    'out_act_fun': 'linear', \n",
    "    'cost_fun': 'eucl', \n",
    "    'ridge_lambda': 1e-08, \n",
    "    'lasso_lambda': None, \n",
    "    'decay_max_steps': None, \n",
    "    'decay_min_value': 10, \n",
    "    'es_patience': 30 }\n",
    "\n",
    "if tr_data.shape[0] == 700:\n",
    "    tr_data = pd.concat([tr_data,es_data])\n",
    "ES_STOP = 0.244\n",
    "k_fold(5, tr_data, parameters,None,\"cup\",10,3,es_stop=ES_STOP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5-fold mee validation = **0.560**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 fold without es\n",
    "parameters = {\n",
    "    'eta': 0.0001,\n",
    "    'mb': 1,\n",
    "    'momentum': 0.8, \n",
    "    'n_layers': 3, \n",
    "    'n_neurons': 200, \n",
    "    'epochs': 2000, \n",
    "    'clip_value': None, \n",
    "    'hid_act_fun': 'tanh', \n",
    "    'out_act_fun': 'linear', \n",
    "    'cost_fun': 'eucl', \n",
    "    'ridge_lambda': 1e-08, \n",
    "    'lasso_lambda': None, \n",
    "    'decay_max_steps': None, \n",
    "    'decay_min_value': 10, \n",
    "    'es_patience': 30 }\n",
    "\n",
    "if tr_data.shape[0] == 700:\n",
    "    tr_data = pd.concat([tr_data,es_data])\n",
    "k_fold(5, tr_data, parameters,None,\"cup\",10,3,es_stop=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5-fold mee validation = **0.538**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the best model is the ensemble, now it'll be trained without 5-fold and tested on the internal test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {\n",
    "    \"eta\" : [0.0001,0.0001,0.0001,0.0001,0.0001],\n",
    "    \"mb\" : [1,1,1,8,1],\n",
    "    \"momentum\" : [0.8,0.6,0.9,0.9,0.5],\n",
    "    \"es_stop\": [0.244,0.262,0.256,0.260,0.259],\n",
    "    \"hid_act_fun\" : \"tanh\",\n",
    "    \"out_act_fun\" : \"linear\",\n",
    "    \"cost_fun\" : \"mse\",\n",
    "    \"ridge_lambda\": [1e-8,1e-8,None,None,None]\n",
    "}\n",
    "\n",
    "if tr_data.shape[0] == 700:\n",
    "    tr_data = pd.concat([tr_data,es_data])\n",
    "\n",
    "# now we instantiate the 5 best models        \n",
    "modelStructures = [(3,200),(3,200),(2,200),(3,200),(3,200)]\n",
    "ensemble = Ensemble(modelStructures)\n",
    "test_mse, train_mse, test_mee,train_mee = ensemble.train_models(tr_data,train_params,test_data,\"eucl\",epochs=2000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with the best model we can make prediction on the blind test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ('Input1', 'Input2', 'Input3', 'Input4', 'Input5', 'Input6',\n",
    "             'Input7', 'Input8', 'Input9', 'Input10')\n",
    "\n",
    "test = pd.read_csv(\"../ML-23-PRJ-Package/ML-CUP23-TS.csv\",\n",
    "                   skiprows=7, usecols=[i for i in range(1, 11)], names=col_names)\n",
    "\n",
    "predictions=pd.DataFrame()\n",
    "for input in test.itertuples(index=False, name=None):\n",
    "    predictions=pd.concat([predictions,pd.DataFrame(ensemble.forwardPropagation(input,None,\"tanh\",\"linear\",None,onlyPrediction=True).reshape((1,-1)))],ignore_index=True)\n",
    "predictions.index+=1\n",
    "\n",
    "header =[\"# Giuseppe De Marco, Alberto Dicembre\",\"# Exploding gradients\",\"# ML-CUP23\", \"# 08/07/2024\"]\n",
    "\n",
    "with open(\"Exploding_gradients_ML-CUP23-TS.csv\", 'w', newline='') as f:\n",
    "    for line in header:\n",
    "        f.write(line + '\\n')\n",
    "\n",
    "predictions.to_csv(\"Exploding_gradients_ML-CUP23-TS.csv\",header=False,mode=\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we try instantiating 5 ensable models to calculate the variance on the mee test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {\n",
    "    \"eta\" : [0.0001,0.0001,0.0001,0.0001,0.0001],\n",
    "    \"mb\" : [1,1,1,8,1],\n",
    "    \"momentum\" : [0.8,0.6,0.9,0.9,0.5],\n",
    "    \"es_stop\": [0.244,0.262,0.256,0.260,0.259],\n",
    "    \"hid_act_fun\" : \"tanh\",\n",
    "    \"out_act_fun\" : \"linear\",\n",
    "    \"cost_fun\" : \"mse\",\n",
    "    \"ridge_lambda\": [1e-8,1e-8,None,None,None]\n",
    "}\n",
    "\n",
    "if tr_data.shape[0] == 700:\n",
    "    tr_data = pd.concat([tr_data,es_data])\n",
    "\n",
    "test_mse = []\n",
    "train_mse = []\n",
    "test_mee = []\n",
    "train_mee = []\n",
    "\n",
    "     \n",
    "modelStructures = [(3,200),(3,200),(2,200),(3,200),(3,200)]\n",
    "for i in range(5):\n",
    "    ensemble = Ensemble(modelStructures)\n",
    "    _test_mse, _train_mse, _test_mee, _train_mee = ensemble.train_models(tr_data,train_params,test_data,\"eucl\",epochs=2000)\n",
    "    test_mse.append(_test_mse)\n",
    "    test_mee.append(_test_mee)\n",
    "    train_mse.append(_train_mse)\n",
    "    train_mee.append(_train_mee)\n",
    "\n",
    "train_mse_mean, train_mee_mean, test_mse_mean,test_mee_mean = plot_ensembles(test_mse,train_mse,test_mee,train_mee)\n",
    "var_test_mee = np.array([test_mee[i][-1] for i in range(5)]).var()\n",
    "print(f\"train_MSE = {train_mse_mean[-1]}, test = {test_mse_mean[-1]}\\ntrain_MEE = {train_mee_mean[-1]}, test = {test_mee_mean[-1]}\")\n",
    "print(f\"mee test variance = {var_test_mee}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
