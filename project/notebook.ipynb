{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Creation\n",
    "\n",
    "Let's create a small Neural Network with 3 layers of 10 neurons each for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nn_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAYER 0 \n",
      "node 0 weights = 0.971631133930822, bias = 0.7907146417764657\n",
      "node 1 weights = 0.79621608836787, bias = 0.6586930109208596\n",
      "node 2 weights = 0.5162809688482168, bias = 0.9484134209513755\n",
      "node 3 weights = 0.74183710862914, bias = 0.04903774429717289\n",
      "node 4 weights = 0.7144498696129329, bias = 0.0754544472226013\n",
      "node 5 weights = 0.6865751586863483, bias = 0.28107726712040537\n",
      "node 6 weights = 0.4019779430215714, bias = 0.6473437875469745\n",
      "node 7 weights = 0.03431859891477973, bias = 0.4847130517668875\n",
      "node 8 weights = 0.03512039096325925, bias = 0.22442525092878496\n",
      "node 9 weights = 0.4291963326341034, bias = 0.3574615121392639\n",
      "\n",
      "LAYER 1 \n",
      "node 0 weights = 0.9147588555606168, bias = 0.9557916827451085\n",
      "node 1 weights = 0.19336347940801812, bias = 0.7196280491751138\n",
      "node 2 weights = 0.001967106859697254, bias = 0.06849906938199346\n",
      "node 3 weights = 0.4205216909378219, bias = 0.677971906109168\n",
      "node 4 weights = 0.6487162676244091, bias = 0.6504782387153754\n",
      "node 5 weights = 0.06676074393025, bias = 0.3695175712347981\n",
      "node 6 weights = 0.057440121693162816, bias = 0.11759944436573577\n",
      "node 7 weights = 0.1488669268499614, bias = 0.397867752919991\n",
      "node 8 weights = 0.99695100344842, bias = 0.386119389161675\n",
      "node 9 weights = 0.14783768214782744, bias = 0.6777511919849262\n",
      "\n",
      "LAYER 2 \n",
      "node 0 weights = 0.39779289653368277, bias = 0.8824585883685641\n",
      "node 1 weights = 0.9848678289185436, bias = 0.29933833626056505\n",
      "node 2 weights = 0.5110956764744744, bias = 0.44321954535897734\n",
      "node 3 weights = 0.40939249958758117, bias = 0.4149215942236605\n",
      "node 4 weights = 0.22201853998514798, bias = 0.07326561350413685\n",
      "node 5 weights = 0.14373113321504727, bias = 0.24847627970950403\n",
      "node 6 weights = 0.40879813932567244, bias = 0.2891150277583696\n",
      "node 7 weights = 0.035778478178476236, bias = 0.8354168016862853\n",
      "node 8 weights = 0.5024682586774262, bias = 0.36911233124736964\n",
      "node 9 weights = 0.6178351135264435, bias = 0.09305543303339159\n",
      "\n",
      "LAYER 3 \n",
      "node 0 weights = 0.3450335237783173, bias = 0.516690556852793\n",
      "node 1 weights = 0.8534245436104103, bias = 0.020046651960231365\n",
      "node 2 weights = 0.6948875528108024, bias = 0.9867563691150276\n",
      "node 3 weights = 0.9106927242600898, bias = 0.8360209061227297\n",
      "node 4 weights = 0.6379454870740761, bias = 0.07848443495806767\n",
      "node 5 weights = 0.3335999455949432, bias = 0.8409922947805791\n",
      "node 6 weights = 0.08328643527755897, bias = 0.2921649899456831\n",
      "node 7 weights = 0.37950931012826183, bias = 0.7967630442461335\n",
      "node 8 weights = 0.914309599413454, bias = 0.7159663285313503\n",
      "node 9 weights = 0.8423569339539638, bias = 0.06515233571095302\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_layers = 3\n",
    "n_neurons = 10\n",
    "net = NeuralNetwork()\n",
    "weights = np.random.rand(n_neurons)\n",
    "biases = np.random.rand(n_neurons)\n",
    "input_layer = Layer(weights=weights, biases=biases)\n",
    "net.add_layer(input_layer)\n",
    "\n",
    "for i in range(0, n_layers):\n",
    "    weights = np.random.rand(n_neurons)\n",
    "    biases = np.random.rand(n_neurons)\n",
    "    layer = Layer(weights, biases)\n",
    "    net.add_layer(layer)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input1</th>\n",
       "      <th>Input2</th>\n",
       "      <th>Input3</th>\n",
       "      <th>Input4</th>\n",
       "      <th>Input5</th>\n",
       "      <th>Input6</th>\n",
       "      <th>Input7</th>\n",
       "      <th>Input8</th>\n",
       "      <th>Input9</th>\n",
       "      <th>Input10</th>\n",
       "      <th>TARGET_x</th>\n",
       "      <th>TARGET_y</th>\n",
       "      <th>TARGET_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.917280</td>\n",
       "      <td>-0.712727</td>\n",
       "      <td>-0.989904</td>\n",
       "      <td>0.992819</td>\n",
       "      <td>0.993649</td>\n",
       "      <td>0.995543</td>\n",
       "      <td>0.711074</td>\n",
       "      <td>0.407645</td>\n",
       "      <td>-0.688548</td>\n",
       "      <td>0.616890</td>\n",
       "      <td>7.897453</td>\n",
       "      <td>-35.936382</td>\n",
       "      <td>21.077147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.858784</td>\n",
       "      <td>0.998755</td>\n",
       "      <td>-0.998396</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>0.316503</td>\n",
       "      <td>-0.951897</td>\n",
       "      <td>-0.163139</td>\n",
       "      <td>0.980982</td>\n",
       "      <td>0.661759</td>\n",
       "      <td>-0.800155</td>\n",
       "      <td>-9.330632</td>\n",
       "      <td>19.901571</td>\n",
       "      <td>6.069154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.990441</td>\n",
       "      <td>0.958726</td>\n",
       "      <td>-0.998675</td>\n",
       "      <td>0.997216</td>\n",
       "      <td>0.987166</td>\n",
       "      <td>0.356483</td>\n",
       "      <td>-0.279689</td>\n",
       "      <td>0.599163</td>\n",
       "      <td>-0.684630</td>\n",
       "      <td>0.922901</td>\n",
       "      <td>14.849400</td>\n",
       "      <td>3.374090</td>\n",
       "      <td>19.667479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.937117</td>\n",
       "      <td>0.984474</td>\n",
       "      <td>-0.612420</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>0.728623</td>\n",
       "      <td>-0.539962</td>\n",
       "      <td>-0.165939</td>\n",
       "      <td>0.999352</td>\n",
       "      <td>-0.921444</td>\n",
       "      <td>-0.974766</td>\n",
       "      <td>-46.591854</td>\n",
       "      <td>13.734777</td>\n",
       "      <td>17.953600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.906628</td>\n",
       "      <td>-0.884567</td>\n",
       "      <td>-0.932487</td>\n",
       "      <td>0.941037</td>\n",
       "      <td>0.978134</td>\n",
       "      <td>0.998179</td>\n",
       "      <td>0.749606</td>\n",
       "      <td>-0.590599</td>\n",
       "      <td>-0.508268</td>\n",
       "      <td>0.691798</td>\n",
       "      <td>8.217500</td>\n",
       "      <td>-45.885254</td>\n",
       "      <td>14.894251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Input1    Input2    Input3    Input4    Input5    Input6    Input7  \\\n",
       "0 -0.917280 -0.712727 -0.989904  0.992819  0.993649  0.995543  0.711074   \n",
       "1 -0.858784  0.998755 -0.998396  0.999909  0.316503 -0.951897 -0.163139   \n",
       "2 -0.990441  0.958726 -0.998675  0.997216  0.987166  0.356483 -0.279689   \n",
       "3  0.937117  0.984474 -0.612420  0.999812  0.728623 -0.539962 -0.165939   \n",
       "4 -0.906628 -0.884567 -0.932487  0.941037  0.978134  0.998179  0.749606   \n",
       "\n",
       "     Input8    Input9   Input10   TARGET_x   TARGET_y   TARGET_z  \n",
       "0  0.407645 -0.688548  0.616890   7.897453 -35.936382  21.077147  \n",
       "1  0.980982  0.661759 -0.800155  -9.330632  19.901571   6.069154  \n",
       "2  0.599163 -0.684630  0.922901  14.849400   3.374090  19.667479  \n",
       "3  0.999352 -0.921444 -0.974766 -46.591854  13.734777  17.953600  \n",
       "4 -0.590599 -0.508268  0.691798   8.217500 -45.885254  14.894251  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ('Input1', 'Input2', 'Input3', 'Input4', 'Input5', 'Input6', 'Input7', 'Input8', 'Input9', 'Input10', 'TARGET_x', 'TARGET_y', 'TARGET_z')\n",
    "data = pd.read_csv(\"../ML-23-PRJ-Package/ML-CUP23-TR.csv\", skiprows=7, usecols = [i for i in range (1, 14)], names = col_names)\n",
    "\n",
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
