{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Creation\n",
    "\n",
    "Let's create a small Neural Network with 3 hidden layers for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nn_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT LAYER: \n",
      "NODE 0 WEIGHTS = 1.0996595958871132,  BIAS = 0.0\n",
      "NODE 1 WEIGHTS = 0.6552637307225978,  BIAS = 0.0\n",
      "NODE 2 WEIGHTS = 0.640131526097592,  BIAS = 0.0\n",
      "NODE 3 WEIGHTS = -1.6169560443108344,  BIAS = 0.0\n",
      "NODE 4 WEIGHTS = -0.024326124398935636,  BIAS = 0.0\n",
      "NODE 5 WEIGHTS = -0.7380309092056887,  BIAS = 0.0\n",
      "NODE 6 WEIGHTS = 0.27992459904323824,  BIAS = 0.0\n",
      "NODE 7 WEIGHTS = -0.09815038964295794,  BIAS = 0.0\n",
      "NODE 8 WEIGHTS = 0.9101789080925919,  BIAS = 0.0\n",
      "NODE 9 WEIGHTS = 0.31721821519130206,  BIAS = 0.0\n",
      "\n",
      "LAYER 0 \n",
      "NODE 0 WEIGHTS = 0.7863279621089762, 0.3791517355550818, -0.4635959746460942, 0.23218103620027578, -0.5428614760167177, -2.0699850250135325, -0.13288057758695562, 1.079618592036821, 0.14195316332077967, -1.3833639553950554,  BIAS = 0.0\n",
      "NODE 1 WEIGHTS = -0.46641909673594306, 2.259308950690852, 0.4814814737734622, -0.5973160689653627, 0.4160500462614255, 0.42625873077810095, -0.2977908794017283, -0.8133642592042029, -0.3193284171450952, -1.582938397335082,  BIAS = 0.0\n",
      "NODE 2 WEIGHTS = -0.9444462559182504, -0.04225715166064269, -1.5407970144446248, -0.237921729736007, -1.1561824318219127, 0.6769080350302455, -0.3090129690471222, -1.466424327802514, 0.6915387510701866, 0.6103793791072052,  BIAS = 0.0\n",
      "NODE 3 WEIGHTS = -0.41004969320254847, -0.955945000492777, 0.06326199420033171, -1.4240609089825316, 0.7811981017099934, -0.637437025552229, -1.6760038063299767, 0.5210648764527586, 0.6947491436560059, -1.188859257784029,  BIAS = 0.0\n",
      "NODE 4 WEIGHTS = -0.017020413861440594, -0.34598177569938643, 0.1565065379653756, -0.49331988336219407, 1.4944845444913688, -0.39727181432879766, 1.15233156478312, -0.5757879698130661, -0.7255973784635843, -0.5068163542986875,  BIAS = 0.0\n",
      "\n",
      "LAYER 1 \n",
      "NODE 0 WEIGHTS = -0.5963140384505081, 0.5238910238342056, 0.3990463456401302, -0.65240858238702, -2.0306844677814944,  BIAS = 0.0\n",
      "NODE 1 WEIGHTS = -0.05256729626954629, 0.08842208704466141, -2.77259275642665, -0.3909533751876011, 2.0644928613593194,  BIAS = 0.0\n",
      "NODE 2 WEIGHTS = -1.936279805846507, -0.3108861716984717, 1.9559123082506942, 0.49374177734918845, -0.11054065723247261,  BIAS = 0.0\n",
      "NODE 3 WEIGHTS = 0.18877859679382855, 0.09740016626878341, 0.39009332268792646, -0.11610393903436653, 1.0201727117157997,  BIAS = 0.0\n",
      "\n",
      "LAYER 2 \n",
      "NODE 0 WEIGHTS = -0.6920498477843912, 0.6088438344754508, 0.6898181645347884, -0.4810271184607877,  BIAS = 0.0\n",
      "NODE 1 WEIGHTS = 1.5363770542457977, -1.0452533661469547, 1.3018462295649984, 2.303916697683942,  BIAS = 0.0\n",
      "NODE 2 WEIGHTS = 0.28634368889227957, 1.2111452896827009, -0.6280875596415789, -1.0600158227215473,  BIAS = 0.0\n",
      "\n",
      "\n",
      "OUTPUT LAYER: \n",
      "NODE 0 WEIGHTS = -0.13594970067832082, 0.5829536797532936, -1.3065268517353166,  BIAS = 0.0\n",
      "NODE 1 WEIGHTS = 1.1368913626026953, -0.3994490292628752, 1.658130679618188,  BIAS = 0.0\n",
      "NODE 2 WEIGHTS = 0.0977249677148556, 0.37005588784751875, -0.11816404512856976,  BIAS = 0.0\n",
      " \n",
      "25\n"
     ]
    }
   ],
   "source": [
    "n_hidden_layers = 3\n",
    "n_neurons = 5\n",
    "n_outputs = 3\n",
    "n_inputs = 10\n",
    "\n",
    "net = NeuralNetwork()\n",
    "net.add_input_layer(10)\n",
    "\n",
    "net.add_hidden_layer(10, 5)\n",
    "net.add_hidden_layer(5, 4)\n",
    "net.add_hidden_layer(4, 3)\n",
    "\n",
    "net.add_output_layer(3, 3)\n",
    "\n",
    "\n",
    "print(net)\n",
    "print(net.number_of_nodes())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input1</th>\n",
       "      <th>Input2</th>\n",
       "      <th>Input3</th>\n",
       "      <th>Input4</th>\n",
       "      <th>Input5</th>\n",
       "      <th>Input6</th>\n",
       "      <th>Input7</th>\n",
       "      <th>Input8</th>\n",
       "      <th>Input9</th>\n",
       "      <th>Input10</th>\n",
       "      <th>TARGET_x</th>\n",
       "      <th>TARGET_y</th>\n",
       "      <th>TARGET_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.917280</td>\n",
       "      <td>-0.712727</td>\n",
       "      <td>-0.989904</td>\n",
       "      <td>0.992819</td>\n",
       "      <td>0.993649</td>\n",
       "      <td>0.995543</td>\n",
       "      <td>0.711074</td>\n",
       "      <td>0.407645</td>\n",
       "      <td>-0.688548</td>\n",
       "      <td>0.616890</td>\n",
       "      <td>7.897453</td>\n",
       "      <td>-35.936382</td>\n",
       "      <td>21.077147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.858784</td>\n",
       "      <td>0.998755</td>\n",
       "      <td>-0.998396</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>0.316503</td>\n",
       "      <td>-0.951897</td>\n",
       "      <td>-0.163139</td>\n",
       "      <td>0.980982</td>\n",
       "      <td>0.661759</td>\n",
       "      <td>-0.800155</td>\n",
       "      <td>-9.330632</td>\n",
       "      <td>19.901571</td>\n",
       "      <td>6.069154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.990441</td>\n",
       "      <td>0.958726</td>\n",
       "      <td>-0.998675</td>\n",
       "      <td>0.997216</td>\n",
       "      <td>0.987166</td>\n",
       "      <td>0.356483</td>\n",
       "      <td>-0.279689</td>\n",
       "      <td>0.599163</td>\n",
       "      <td>-0.684630</td>\n",
       "      <td>0.922901</td>\n",
       "      <td>14.849400</td>\n",
       "      <td>3.374090</td>\n",
       "      <td>19.667479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.937117</td>\n",
       "      <td>0.984474</td>\n",
       "      <td>-0.612420</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>0.728623</td>\n",
       "      <td>-0.539962</td>\n",
       "      <td>-0.165939</td>\n",
       "      <td>0.999352</td>\n",
       "      <td>-0.921444</td>\n",
       "      <td>-0.974766</td>\n",
       "      <td>-46.591854</td>\n",
       "      <td>13.734777</td>\n",
       "      <td>17.953600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.906628</td>\n",
       "      <td>-0.884567</td>\n",
       "      <td>-0.932487</td>\n",
       "      <td>0.941037</td>\n",
       "      <td>0.978134</td>\n",
       "      <td>0.998179</td>\n",
       "      <td>0.749606</td>\n",
       "      <td>-0.590599</td>\n",
       "      <td>-0.508268</td>\n",
       "      <td>0.691798</td>\n",
       "      <td>8.217500</td>\n",
       "      <td>-45.885254</td>\n",
       "      <td>14.894251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-0.803560</td>\n",
       "      <td>-0.878859</td>\n",
       "      <td>-0.978391</td>\n",
       "      <td>0.957539</td>\n",
       "      <td>0.996655</td>\n",
       "      <td>0.996924</td>\n",
       "      <td>-0.226305</td>\n",
       "      <td>0.097814</td>\n",
       "      <td>-0.922666</td>\n",
       "      <td>0.934153</td>\n",
       "      <td>15.389553</td>\n",
       "      <td>-41.068806</td>\n",
       "      <td>27.513502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.718841</td>\n",
       "      <td>0.995748</td>\n",
       "      <td>-0.942678</td>\n",
       "      <td>0.999929</td>\n",
       "      <td>0.747763</td>\n",
       "      <td>-0.808726</td>\n",
       "      <td>0.176132</td>\n",
       "      <td>0.999100</td>\n",
       "      <td>-0.753970</td>\n",
       "      <td>-0.969009</td>\n",
       "      <td>-36.228770</td>\n",
       "      <td>13.067430</td>\n",
       "      <td>11.672133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-0.977912</td>\n",
       "      <td>-0.971108</td>\n",
       "      <td>0.956233</td>\n",
       "      <td>-0.979524</td>\n",
       "      <td>0.222033</td>\n",
       "      <td>0.986609</td>\n",
       "      <td>0.658273</td>\n",
       "      <td>-0.987310</td>\n",
       "      <td>0.937697</td>\n",
       "      <td>0.143420</td>\n",
       "      <td>7.265506</td>\n",
       "      <td>-53.497242</td>\n",
       "      <td>2.815666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.284803</td>\n",
       "      <td>-0.988684</td>\n",
       "      <td>-0.427197</td>\n",
       "      <td>0.883317</td>\n",
       "      <td>0.993302</td>\n",
       "      <td>0.999500</td>\n",
       "      <td>-0.019456</td>\n",
       "      <td>-0.648110</td>\n",
       "      <td>-0.955231</td>\n",
       "      <td>0.901298</td>\n",
       "      <td>5.545274</td>\n",
       "      <td>-63.348396</td>\n",
       "      <td>27.989340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-0.987580</td>\n",
       "      <td>0.993488</td>\n",
       "      <td>-0.998944</td>\n",
       "      <td>0.999703</td>\n",
       "      <td>0.936830</td>\n",
       "      <td>-0.564176</td>\n",
       "      <td>0.262568</td>\n",
       "      <td>0.892081</td>\n",
       "      <td>-0.198204</td>\n",
       "      <td>0.494586</td>\n",
       "      <td>6.160610</td>\n",
       "      <td>8.321016</td>\n",
       "      <td>13.021444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Input1    Input2    Input3    Input4    Input5    Input6    Input7  \\\n",
       "0   -0.917280 -0.712727 -0.989904  0.992819  0.993649  0.995543  0.711074   \n",
       "1   -0.858784  0.998755 -0.998396  0.999909  0.316503 -0.951897 -0.163139   \n",
       "2   -0.990441  0.958726 -0.998675  0.997216  0.987166  0.356483 -0.279689   \n",
       "3    0.937117  0.984474 -0.612420  0.999812  0.728623 -0.539962 -0.165939   \n",
       "4   -0.906628 -0.884567 -0.932487  0.941037  0.978134  0.998179  0.749606   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995 -0.803560 -0.878859 -0.978391  0.957539  0.996655  0.996924 -0.226305   \n",
       "996  0.718841  0.995748 -0.942678  0.999929  0.747763 -0.808726  0.176132   \n",
       "997 -0.977912 -0.971108  0.956233 -0.979524  0.222033  0.986609  0.658273   \n",
       "998  0.284803 -0.988684 -0.427197  0.883317  0.993302  0.999500 -0.019456   \n",
       "999 -0.987580  0.993488 -0.998944  0.999703  0.936830 -0.564176  0.262568   \n",
       "\n",
       "       Input8    Input9   Input10   TARGET_x   TARGET_y   TARGET_z  \n",
       "0    0.407645 -0.688548  0.616890   7.897453 -35.936382  21.077147  \n",
       "1    0.980982  0.661759 -0.800155  -9.330632  19.901571   6.069154  \n",
       "2    0.599163 -0.684630  0.922901  14.849400   3.374090  19.667479  \n",
       "3    0.999352 -0.921444 -0.974766 -46.591854  13.734777  17.953600  \n",
       "4   -0.590599 -0.508268  0.691798   8.217500 -45.885254  14.894251  \n",
       "..        ...       ...       ...        ...        ...        ...  \n",
       "995  0.097814 -0.922666  0.934153  15.389553 -41.068806  27.513502  \n",
       "996  0.999100 -0.753970 -0.969009 -36.228770  13.067430  11.672133  \n",
       "997 -0.987310  0.937697  0.143420   7.265506 -53.497242   2.815666  \n",
       "998 -0.648110 -0.955231  0.901298   5.545274 -63.348396  27.989340  \n",
       "999  0.892081 -0.198204  0.494586   6.160610   8.321016  13.021444  \n",
       "\n",
       "[1000 rows x 13 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ('Input1', 'Input2', 'Input3', 'Input4', 'Input5', 'Input6', 'Input7', 'Input8', 'Input9', 'Input10', 'TARGET_x', 'TARGET_y', 'TARGET_z')\n",
    "data = pd.read_csv(\"../ML-23-PRJ-Package/ML-CUP23-TR.csv\", skiprows=7, usecols = [i for i in range (1, 14)], names = col_names)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Preparing Dataframe\n",
    "i.e. creating the training set by removing non-training columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total Error pre-training = 0.13561049276641168\n",
      "1000\n",
      "Epoch = 1, total Error post-training = 4097.921418900924\n",
      "1000\n",
      "Epoch = 2, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 3, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 4, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 5, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 6, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 7, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 8, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 9, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 10, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 11, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 12, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 13, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 14, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 15, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 16, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 17, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 18, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 19, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 20, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 21, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 22, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 23, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 24, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 25, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 26, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 27, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 28, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 29, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 30, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 31, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 32, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 33, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 34, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 35, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 36, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 37, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 38, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 39, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 40, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 41, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 42, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 43, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 44, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 45, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 46, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 47, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 48, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 49, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 50, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 51, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 52, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 53, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 54, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 55, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 56, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 57, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 58, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 59, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 60, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 61, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 62, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 63, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 64, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 65, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 66, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 67, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 68, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 69, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 70, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 71, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 72, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 73, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 74, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 75, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 76, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 77, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 78, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 79, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 80, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 81, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 82, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 83, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 84, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 85, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 86, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 87, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 88, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 89, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 90, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 91, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 92, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 93, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 94, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 95, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 96, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 97, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 98, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 99, total Error post-training = 0.1407902617393093\n",
      "1000\n",
      "Epoch = 100, total Error post-training = 0.1407902617393093\n",
      "end Training\n",
      "INPUT LAYER: \n",
      "NODE 0 WEIGHTS = 1.0996595958871132,  BIAS = 0.0\n",
      "NODE 1 WEIGHTS = 0.6552637307225978,  BIAS = 0.0\n",
      "NODE 2 WEIGHTS = 0.640131526097592,  BIAS = 0.0\n",
      "NODE 3 WEIGHTS = -1.6169560443108344,  BIAS = 0.0\n",
      "NODE 4 WEIGHTS = -0.024326124398935636,  BIAS = 0.0\n",
      "NODE 5 WEIGHTS = -0.7380309092056887,  BIAS = 0.0\n",
      "NODE 6 WEIGHTS = 0.27992459904323824,  BIAS = 0.0\n",
      "NODE 7 WEIGHTS = -0.09815038964295794,  BIAS = 0.0\n",
      "NODE 8 WEIGHTS = 0.9101789080925919,  BIAS = 0.0\n",
      "NODE 9 WEIGHTS = 0.31721821519130206,  BIAS = 0.0\n",
      "\n",
      "LAYER 0 \n",
      "NODE 0 WEIGHTS = -11600.582620543975, -11600.98979677053, -11601.83254448073, -11601.136767469885, -11601.911809982103, -11603.438933531099, -11601.501829083672, -11600.289329914049, -11601.226995342764, -11602.75231246148,  BIAS = -11601.368948506086\n",
      "NODE 1 WEIGHTS = -38578.66024945049, -38575.93452140306, -38577.712348879984, -38578.79114642272, -38577.77778030749, -38577.76757162298, -38578.49162123316, -38579.00719461296, -38578.5131587709, -38579.77676875109,  BIAS = -38578.19383035375\n",
      "NODE 2 WEIGHTS = -68376.15809234403, -68375.25590323978, -68376.75444310256, -68375.45156781786, -68376.36982851994, -68374.5367380531, -68375.52265905717, -68376.68007041593, -68374.52210733705, -68374.60326670902,  BIAS = -68375.21364608812\n",
      "NODE 3 WEIGHTS = -35316.35623201109, -35316.902127318375, -35315.88292032368, -35317.37024322687, -35315.16498421617, -35316.58361934344, -35317.622186124216, -35315.42511744143, -35315.25143317423, -35317.13504157567,  BIAS = -35315.946182317886\n",
      "NODE 4 WEIGHTS = -131.59732161220583, -131.92628297404377, -131.423794660379, -132.0736210817066, -130.08581665385302, -131.9775730126732, -130.42796963356128, -132.15608916815745, -132.30589857680798, -132.08711755264306,  BIAS = -131.5803011983444\n",
      "\n",
      "LAYER 1 \n",
      "NODE 0 WEIGHTS = -4994.632510096118, -4993.512305033833, -4993.637149712027, -4994.688604640054, -4996.066880525449,  BIAS = -4994.036196057667\n",
      "NODE 1 WEIGHTS = -6.619449383601861, -6.478460000287653, -9.339474843758964, -6.957835462519915, -4.502389225972995,  BIAS = -6.566882087332314\n",
      "NODE 2 WEIGHTS = -4564.990878703718, -4563.36548506957, -4561.098686589621, -4562.560857120522, -4563.165139555104,  BIAS = -4563.054598897871\n",
      "NODE 3 WEIGHTS = -6447.1935276027625, -6447.284906033287, -6446.9922128768685, -6447.498410138591, -6446.36213348784,  BIAS = -6447.382306199556\n",
      "\n",
      "LAYER 2 \n",
      "NODE 0 WEIGHTS = -4.637077350166252, -3.33618366790641, -3.2552093378470723, -4.426054620842648,  BIAS = -3.9450275023818606\n",
      "NODE 1 WEIGHTS = -1878.9308170906843, -1881.5124475110772, -1879.1653479153651, -1878.1632774472462,  BIAS = -1880.46719414493\n",
      "NODE 2 WEIGHTS = -2.7444641996796717, -1.8196625988892505, -3.6588954482135305, -4.090823711293499,  BIAS = -3.0308078885719514\n",
      "\n",
      "\n",
      "OUTPUT LAYER: \n",
      "NODE 0 WEIGHTS = -226.13228255005455, -225.41337916962294, -227.30285970111154,  BIAS = -225.99633284937622\n",
      "NODE 1 WEIGHTS = -313.5376126084217, -315.07395300028725, -313.0163732914062,  BIAS = -314.67450397102436\n",
      "NODE 2 WEIGHTS = -190.56995514799144, -190.29762422785882, -190.78584416083493,  BIAS = -190.6676801157064\n",
      " \n",
      "[[ 1.0996596   0.65526373  0.64013153 -1.61695604 -0.02432612 -0.73803091\n",
      "   0.2799246  -0.09815039  0.91017891  0.31721822]]\n"
     ]
    }
   ],
   "source": [
    "tr_data_X = data[['Input1', 'Input2', 'Input3', 'Input4', 'Input5', 'Input6', 'Input7', 'Input8', 'Input9', 'Input10']]\n",
    "\n",
    "tr_data_Y = data[['TARGET_x', 'TARGET_y', 'TARGET_z']]\n",
    "\n",
    "net.train(tr_data_X,tr_data_Y,epochs=100)\n",
    "\n",
    "print(net)\n",
    "print(net.input_layer.weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.hidden_layers[0].acc_bias_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  7.897453 -35.936382  21.077147]\n",
      "[-0. -0. -0.]\n"
     ]
    }
   ],
   "source": [
    "for row,label in zip(tr_data_X.itertuples(index = False, name = None),tr_data_Y.itertuples(index=False,name=None)):\n",
    "    #Forward propagation\n",
    "    net.forwardPropagation(row,label)\n",
    "    print(np.array(label))\n",
    "    print(net.output_layer.output)\n",
    "    break\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
